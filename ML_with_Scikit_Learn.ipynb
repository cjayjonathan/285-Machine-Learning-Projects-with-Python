{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML with Scikit Learn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeyJKTTAENaFRAMsLGL5dC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjayjonathan/285-Machine-Learning-Projects-with-Python/blob/main/ML_with_Scikit_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDqeoQSC90tq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# KNN: Fit\n",
        "# Import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "\n",
        "# Create arrays for the features and the target variable\n",
        "y = churn_df[\"churn\"].values\n",
        "X = churn_df[[\"account_length\", \"customer_service_calls\"]].values\n",
        "\n",
        "# Create a KNN classifier with 6 neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "# Fit the classifier to the data\n",
        "knn.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN: Predict\n",
        "\n",
        "# Predict the labels for the X_new\n",
        "y_pred = knn.predict(X_new)\n",
        "\n",
        "# Print the predictions for X_new\n",
        "print(\"Predictions: {}\".format(y_pred)) \n"
      ],
      "metadata": {
        "id": "j2DB9XsG97No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split + computing accuracy\n",
        "# Import the module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = churn_df.drop(\"churn\", axis=1).values\n",
        "y = churn_df[\"churn\"].values\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Print the accuracy\n",
        "print(knn.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "lEO7pOmJ-H8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfitting and underfitting\n",
        "# Create neighbors\n",
        "neighbors = np.arange(1, 13)\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}\n",
        "\n",
        "for neighbor in neighbors:\n",
        "  \n",
        "  \t# Set up a KNN Classifier\n",
        "  \tknn = KNeighborsClassifier(n_neighbors=neighbor)\n",
        "  \n",
        "  \t# Fit the model\n",
        "  \tknn.fit(X_train, y_train)\n",
        "  \n",
        "  \t# Compute accuracy\n",
        "  \ttrain_accuracies[neighbor] = knn.score(X_train, y_train)\n",
        "  \ttest_accuracies[neighbor] = knn.score(X_test, y_test)\n",
        "print(neighbors, '\\n', train_accuracies, '\\n', test_accuracies)"
      ],
      "metadata": {
        "id": "EJuTZd7__njx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing model complexity\n",
        "# Add a title\n",
        "plt.title(\"KNN: Varying Number of Neighbors\")\n",
        "\n",
        "# Plot training accuracies\n",
        "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
        "\n",
        "# Plot test accuracies\n",
        "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Neighbors\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bFHXbdH6SShb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating features\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create X from the radio column's values\n",
        "X = sales_df[\"radio\"].values\n",
        "\n",
        "# Create y from the sales column's values\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "# Reshape X\n",
        "X = X.reshape(-1, 1)\n",
        "\n",
        "# Check the shape of the features and targets\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "G9h5AeCkYV_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a linear regression model\n",
        "\n",
        "# Import LinearRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create the model\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "reg.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = reg.predict(X)\n",
        "\n",
        "print(predictions[:5])"
      ],
      "metadata": {
        "id": "KRlk9cWhcyfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing a linear regression model\n",
        "\n",
        "# Import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(X, y, color=\"blue\")\n",
        "\n",
        "# Create line plot\n",
        "plt.plot(X, predictions, color=\"red\")\n",
        "plt.xlabel(\"Radio Expenditure ($)\")\n",
        "plt.ylabel(\"Sales ($)\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2KUXyGRPdT3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and predict for regression\n",
        "\n",
        "# Create X and y arrays\n",
        "X = sales_df.drop(\"sales\", axis=1).values\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Instantiate the model\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg.predict(X_test)\n",
        "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
      ],
      "metadata": {
        "id": "XGUvQf8IcycA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression performance\n",
        "\n",
        "# Import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Compute R-squared\n",
        "r_squared = reg.score(X_test, y_test)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"R^2: {}\".format(r_squared))\n",
        "print(\"RMSE: {}\".format(rmse))"
      ],
      "metadata": {
        "id": "XBEn9L02orys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print missing values for each column\n",
        "print(music_df.isna().sum().sort_values())\n",
        "\n",
        "# Remove values where less than 5% are missing\n",
        "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
        "\n",
        "# Convert genre to a binary feature\n",
        "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
        "\n",
        "print(music_df.isna().sum().sort_values())\n",
        "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
      ],
      "metadata": {
        "id": "C7ayraLMCOGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation for R-squared\n",
        "\n",
        "# Import the necessary modules\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Create a KFold object\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=5)\n",
        "\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Compute 6-fold cross-validation scores\n",
        "cv_scores = cross_val_score(reg, X, y, cv=kf)\n",
        "\n",
        "# Print scores\n",
        "print(cv_scores)"
      ],
      "metadata": {
        "id": "qOKeqQKF4Edj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing cross-validation metrics\n",
        "\n",
        "# Print the mean\n",
        "print(np.mean(cv_results))\n",
        "\n",
        "# Print the standard deviation\n",
        "print(np.std(cv_results))\n",
        "\n",
        "# Print the 95% confidence interval\n",
        "print(np.quantile(cv_results, [0.025, 0.975]))"
      ],
      "metadata": {
        "id": "C4VpgTi64slU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline for song genre prediction: I\n",
        "\n",
        "# Import modules\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Instantiate an imputer\n",
        "imputer = SimpleImputer()\n",
        "\n",
        "# Instantiate a knn model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Build steps for the pipeline\n",
        "steps = [(\"imputer\", imputer), \n",
        "         (\"knn\", knn)]"
      ],
      "metadata": {
        "id": "ZnxNN4cd2ej0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline for song genre prediction: II\n",
        "\n",
        "steps = [(\"imputer\", imp_mean),\n",
        "        (\"knn\", knn)]\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "9IX4MOXC5XMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Centering and scaling for regression\n",
        "\n",
        "# Import StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create pipeline steps\n",
        "steps = [(\"scaler\", StandardScaler()),\n",
        "         (\"lasso\", Lasso(alpha=0.5))]\n",
        "\n",
        "# Instantiate the pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Calculate and print R-squared\n",
        "print(pipeline.score(X_test, y_test))\n",
        "\n",
        "\n",
        "# Build the steps\n",
        "steps = [(\"scaler\", StandardScaler()),\n",
        "         (\"logreg\", LogisticRegression())]\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# Create the parameter space\n",
        "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
        "                                                    random_state=21)\n",
        "\n",
        "# Instantiate the grid search object\n",
        "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
        "\n",
        "# Fit to the training data\n",
        "cv.fit(X_train, y_train)\n",
        "print(cv.best_score_, \"\\n\", cv.best_params_)\n"
      ],
      "metadata": {
        "id": "vA5bkidkBxBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing regression model performance\n",
        "\n",
        "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
        "results = []\n",
        "\n",
        "# Loop through the models' values\n",
        "for model in models.values():\n",
        "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
        "  \n",
        "  # Perform cross-validation\n",
        "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
        "  \n",
        "  # Append the results\n",
        "  results.append(cv_scores)\n",
        "\n",
        "# Create a box plot of the results\n",
        "plt.boxplot(results, labels=models.keys())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pH4xUJVpOgW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test set\n",
        "\n",
        "# Import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "for name, model in models.items():\n",
        "  \n",
        "  # Fit the model to the training data\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "  \n",
        "  # Make predictions on the test set\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "  # Calculate the test_rmse\n",
        "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))\n",
        "\n"
      ],
      "metadata": {
        "id": "7SZWc8CqPwel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing classification model performance\n",
        "\n",
        "# Create models dictionary\n",
        "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
        "results = []\n",
        "\n",
        "# Loop through the models' values\n",
        "for model in models.values():\n",
        "  \n",
        "  # Instantiate a KFold object\n",
        "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
        "  \n",
        "  # Perform cross-validation\n",
        "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
        "  results.append(cv_results)\n",
        "plt.boxplot(results, labels=models.keys())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p8r_bxKnTH6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline for predicting song popularity\n",
        "\n",
        "# Create steps\n",
        "steps = [(\"imp_mean\", SimpleImputer()), \n",
        "         (\"scaler\", StandardScaler()), \n",
        "         (\"logreg\", LogisticRegression())]\n",
        "\n",
        "# Set up pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
        "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "tuning = GridSearchCV(pipeline, param_grid=params)\n",
        "tuning.fit(X_train, y_train)\n",
        "y_pred = tuning.predict(X_test)\n",
        "\n",
        "# Compute and print performance\n",
        "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "XD4XvT-KTQp5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}